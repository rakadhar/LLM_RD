{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d15d8294-3328-4e07-ad16-8a03e9bbfdb9",
   "metadata": {},
   "source": [
    "# Welcome to your first assignment!\n",
    "\n",
    "Instructions are below. Please give this a try, and look in the solutions folder if you get stuck (or feel free to ask me!)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ada885d9-4d42-4d9b-97f0-74fbbbfe93a9",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left;\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../resources.jpg\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#f71;\">Just before we get to the assignment --</h2>\n",
    "            <span style=\"color:#f71;\">I thought I'd take a second to point you at this page of useful resources for the course. This includes links to all the slides.<br/>\n",
    "            <a href=\"https://edwarddonner.com/2024/11/13/llm-engineering-resources/\">https://edwarddonner.com/2024/11/13/llm-engineering-resources/</a><br/>\n",
    "            Please keep this bookmarked, and I'll continue to add more useful links there over time.\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e9fa1fc-eac5-4d1d-9be4-541b3f2b3458",
   "metadata": {},
   "source": [
    "# HOMEWORK EXERCISE ASSIGNMENT\n",
    "\n",
    "Upgrade the day 1 project to summarize a webpage to use an Open Source model running locally via Ollama rather than OpenAI\n",
    "\n",
    "You'll be able to use this technique for all subsequent projects if you'd prefer not to use paid APIs.\n",
    "\n",
    "**Benefits:**\n",
    "1. No API charges - open-source\n",
    "2. Data doesn't leave your box\n",
    "\n",
    "**Disadvantages:**\n",
    "1. Significantly less power than Frontier Model\n",
    "\n",
    "## Recap on installation of Ollama\n",
    "\n",
    "Simply visit [ollama.com](https://ollama.com) and install!\n",
    "\n",
    "Once complete, the ollama server should already be running locally.  \n",
    "If you visit:  \n",
    "[http://localhost:11434/](http://localhost:11434/)\n",
    "\n",
    "You should see the message `Ollama is running`.  \n",
    "\n",
    "If not, bring up a new Terminal (Mac) or Powershell (Windows) and enter `ollama serve`  \n",
    "And in another Terminal (Mac) or Powershell (Windows), enter `ollama pull llama3.2`  \n",
    "Then try [http://localhost:11434/](http://localhost:11434/) again.\n",
    "\n",
    "If Ollama is slow on your machine, try using `llama3.2:1b` as an alternative. Run `ollama pull llama3.2:1b` from a Terminal or Powershell, and change the code below from `MODEL = \"llama3.2\"` to `MODEL = \"llama3.2:1b\"`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e2a9393-7767-488e-a8bf-27c12dca35bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from IPython.display import Markdown, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "29ddd15d-a3c5-4f4e-a678-873f56162724",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "\n",
    "OLLAMA_API = \"http://localhost:11434/api/chat\"\n",
    "HEADERS = {\"Content-Type\": \"application/json\"}\n",
    "MODEL = \"llama3.2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dac0a679-599c-441f-9bf2-ddc73d35b940",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a messages list using the same format that we used for OpenAI\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"Describe some of the business applications of Generative AI\"}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7bb9c624-14f0-4945-a719-8ddb64f66f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "payload = {\n",
    "        \"model\": MODEL,\n",
    "        \"messages\": messages,\n",
    "        \"stream\": False\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "479ff514-e8bd-4985-a572-2ea28bb4fa40",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[?25lpulling manifest â ‹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest â ™ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest â ¹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest â ¸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest â ¼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest â ´ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest \n",
      "pulling dde5aa3fc5ff... 100% â–•â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–� 2.0 GB                         \n",
      "pulling 966de95ca8a6... 100% â–•â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–� 1.4 KB                         \n",
      "pulling fcc5a6bec9da... 100% â–•â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–� 7.7 KB                         \n",
      "pulling a70ff7e570d9... 100% â–•â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–� 6.0 KB                         \n",
      "pulling 56bb8bd477a5... 100% â–•â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–�   96 B                         \n",
      "pulling 34bb5ab01051... 100% â–•â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–�  561 B                         \n",
      "verifying sha256 digest \n",
      "writing manifest \n",
      "success \u001b[?25h\n"
     ]
    }
   ],
   "source": [
    "# Let's just make sure the model is loaded\n",
    "\n",
    "!ollama pull llama3.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "42b9f644-522d-4e05-a691-56e7658c0ea9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generative AI has numerous business applications across various industries, including:\n",
      "\n",
      "1. **Content Generation**: AI-powered tools can create high-quality content such as articles, blog posts, social media posts, and product descriptions, saving time and resources for content creators.\n",
      "2. **Product Design and Development**: Generative AI can assist in designing new products, such as furniture, electronics, or automotive components, by generating 3D models and prototypes.\n",
      "3. **Marketing and Advertising**: AI-generated ads, social media campaigns, and promotional materials can be created quickly and efficiently, allowing businesses to reach a wider audience more effectively.\n",
      "4. **Data Analysis and Visualization**: Generative AI algorithms can analyze large datasets and generate visualizations, such as charts, graphs, and maps, to help businesses understand complex data patterns and trends.\n",
      "5. **Personalized Recommendations**: AI-powered recommendation systems can be used to create personalized product recommendations for customers based on their browsing history, search queries, and purchase behavior.\n",
      "6. **Chatbots and Virtual Assistants**: Generative AI can power chatbots and virtual assistants that provide customer support, answer frequently asked questions, and help with transactions.\n",
      "7. **Image and Video Generation**: AI-powered tools can generate high-quality images and videos for marketing campaigns, product demos, or training purposes.\n",
      "8. **Supply Chain Optimization**: Generative AI algorithms can analyze supply chain data and generate optimized plans for inventory management, logistics, and production planning.\n",
      "9. **Financial Modeling and Analysis**: AI-powered financial modeling tools can help businesses create realistic financial models, forecast revenue and expenses, and identify potential risks.\n",
      "10. **Innovation and R&D**: Generative AI can assist researchers and developers in exploring new ideas, designing prototypes, and testing hypotheses more efficiently.\n",
      "\n",
      "Some specific business examples of generative AI include:\n",
      "\n",
      "* **Salesforce's Genie**: A virtual assistant that uses generative AI to help customers with their sales and customer service needs.\n",
      "* **Adobe's Fresco**: An AI-powered painting app that generates realistic brushstrokes and textures.\n",
      "* **Microsoft's Azure Forms**: A tool that uses generative AI to automate forms and surveys, reducing manual data entry and improving efficiency.\n",
      "* **Amazon's Sumerian**: A cloud-based platform that allows developers to create interactive 3D content using generative AI-powered tools.\n",
      "\n",
      "These are just a few examples of the many business applications of generative AI. As the technology continues to evolve, we can expect to see even more innovative uses across various industries.\n"
     ]
    }
   ],
   "source": [
    "# If this doesn't work for any reason, try the 2 versions in the following cells\n",
    "# And double check the instructions in the 'Recap on installation of Ollama' at the top of this lab\n",
    "# And if none of that works - contact me!\n",
    "\n",
    "response = requests.post(OLLAMA_API, json=payload, headers=HEADERS)\n",
    "print(response.json()['message']['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a021f13-d6a1-4b96-8e18-4eae49d876fe",
   "metadata": {},
   "source": [
    "# Introducing the ollama package\n",
    "\n",
    "And now we'll do the same thing, but using the elegant ollama python package instead of a direct HTTP call.\n",
    "\n",
    "Under the hood, it's making the same call as above to the ollama server running at localhost:11434"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7745b9c4-57dc-4867-9180-61fa5db55eb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generative AI (Generative Artificial Intelligence) has numerous business applications across various industries, including:\n",
      "\n",
      "1. **Content Creation**: Generative AI can generate high-quality content such as articles, social media posts, product descriptions, and more, reducing the need for human writers and editors.\n",
      "2. **Image and Video Generation**: Generative AI can create realistic images and videos that can be used in marketing campaigns, product demos, or even as a form of entertainment.\n",
      "3. **Chatbots and Virtual Assistants**: Generative AI-powered chatbots can engage with customers, provide customer support, and offer personalized recommendations.\n",
      "4. **Recommendation Systems**: Generative AI can analyze user behavior and generate personalized product recommendations, improving customer satisfaction and increasing sales.\n",
      "5. **Predictive Maintenance**: Generative AI can analyze sensor data from machines and predict when maintenance is required, reducing downtime and increasing productivity.\n",
      "6. **Financial Analysis**: Generative AI can analyze large datasets of financial information to identify trends, patterns, and insights that may not be apparent through human analysis.\n",
      "7. **Marketing Automation**: Generative AI can automate marketing tasks such as lead generation, email campaigns, and social media posting, freeing up resources for more strategic work.\n",
      "8. **Language Translation**: Generative AI can generate translations in real-time, improving communication with international customers or partners.\n",
      "9. **Customer Service Automation**: Generative AI-powered customer service platforms can handle basic customer inquiries and provide personalized support.\n",
      "10. **Design and Architecture**: Generative AI can assist in designing products, buildings, and infrastructure by generating 3D models, blueprints, and other architectural concepts.\n",
      "\n",
      "Some notable business applications of Generative AI include:\n",
      "\n",
      "* **IBM's Watson**: Uses generative AI to analyze large datasets and provide insights for businesses.\n",
      "* **Google's AI-powered Content Creation Tool**: Generates high-quality content such as articles, social media posts, and product descriptions.\n",
      "* **Microsoft's Azure Machine Learning**: Provides a platform for building, training, and deploying machine learning models using generative AI.\n",
      "* **Amazon's Alexa**: Uses generative AI to power its virtual assistant and provide personalized recommendations.\n",
      "\n",
      "These are just a few examples of the many business applications of Generative AI. As the technology continues to evolve, we can expect to see even more innovative uses across various industries.\n"
     ]
    }
   ],
   "source": [
    "import ollama\n",
    "\n",
    "response = ollama.chat(model=MODEL, messages=messages)\n",
    "print(response['message']['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4704e10-f5fb-4c15-a935-f046c06fb13d",
   "metadata": {},
   "source": [
    "## Alternative approach - using OpenAI python library to connect to Ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "23057e00-b6fc-4678-93a9-6b31cb704bff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generative AI has numerous business applications across various industries, including:\n",
      "\n",
      "1. **Content Generation**: AI-powered tools can generate high-quality content such as blog posts, product descriptions, and social media posts, reducing the need for human writers and editors.\n",
      "2. **Marketing Automation**: Generative AI can create personalized marketing campaigns, target-specific audiences, and optimize ads for better performance.\n",
      "3. **Product Design**: Generative AI can design new products, packaging, and user interfaces, saving time and resources for product development teams.\n",
      "4. **Document Generation**: AI-powered tools can generate contracts, invoices, and other documents, streamlining document creation and reducing errors.\n",
      "5. **Chatbots and Virtual Assistants**: Generative AI can power chatbots and virtual assistants, providing 24/7 customer support and automating routine tasks.\n",
      "6. **Image and Video Generation**: AI can generate high-quality images and videos for various applications, such as product visualization, social media, and advertising.\n",
      "7. **Speech Synthesis**: Generative AI can create realistic audio tracks, voice-overs, and narrations for multimedia content.\n",
      "8. **Music Composition**: AI-powered tools can compose music, sounds, and sound effects for film scores, video games, and other creative projects.\n",
      "9. **Data Analytics and Visualization**: Generative AI can generate insights, trends, and visualizations to help business owners make data-driven decisions.\n",
      "10. **Cybersecurity Threat Intelligence**: AI-powered systems can analyze network traffic, identify potential threats, and provide recommendations for improving cybersecurity.\n",
      "\n",
      "Industry-specific applications:\n",
      "\n",
      "1. **Healthcare**: Generative AI can analyze medical images, diagnose diseases, and suggest personalized treatment plans.\n",
      "2. **Finance**: AI-powered tools can generate investment reports, detect fraud, and optimize portfolio management.\n",
      "3. **Education**: Generative AI can create adaptive learning platforms, develop personalized lesson plans, and grade assignments.\n",
      "4. **Manufacturing**: AI-powered systems can design production lines, optimize manufacturing processes, and predict equipment failures.\n",
      "5. **Retail**: Generative AI can analyze customer behavior, generate customized recommendations, and optimize pricing strategies.\n",
      "\n",
      "By leveraging generative AI capabilities, businesses can:\n",
      "\n",
      "* Automate repetitive tasks\n",
      "* Enhance innovation and creativity\n",
      "* Improve decision-making with data-driven insights\n",
      "* Increase efficiency and productivity\n",
      "* Reduce costs and improve customer satisfaction\n",
      "\n",
      "However, it's essential to consider the limitations and potential risks associated with generative AI, such as bias, privacy concerns, and job displacement.\n"
     ]
    }
   ],
   "source": [
    "# There's actually an alternative approach that some people might prefer\n",
    "# You can use the OpenAI client python library to call Ollama:\n",
    "\n",
    "from openai import OpenAI\n",
    "ollama_via_openai = OpenAI(base_url='http://localhost:11434/v1', api_key='ollama')\n",
    "\n",
    "response = ollama_via_openai.chat.completions.create(\n",
    "    model=MODEL,\n",
    "    messages=messages\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f9e22da-b891-41f6-9ac9-bd0c0a5f4f44",
   "metadata": {},
   "source": [
    "## Are you confused about why that works?\n",
    "\n",
    "It seems strange, right? We just used OpenAI code to call Ollama?? What's going on?!\n",
    "\n",
    "Here's the scoop:\n",
    "\n",
    "The python class `OpenAI` is simply code written by OpenAI engineers that makes calls over the internet to an endpoint.  \n",
    "\n",
    "When you call `openai.chat.completions.create()`, this python code just makes a web request to the following url: \"https://api.openai.com/v1/chat/completions\"\n",
    "\n",
    "Code like this is known as a \"client library\" - it's just wrapper code that runs on your machine to make web requests. The actual power of GPT is running on OpenAI's cloud behind this API, not on your computer!\n",
    "\n",
    "OpenAI was so popular, that lots of other AI providers provided identical web endpoints, so you could use the same approach.\n",
    "\n",
    "So Ollama has an endpoint running on your local box at http://localhost:11434/v1/chat/completions  \n",
    "And in week 2 we'll discover that lots of other providers do this too, including Gemini and DeepSeek.\n",
    "\n",
    "And then the team at OpenAI had a great idea: they can extend their client library so you can specify a different 'base url', and use their library to call any compatible API.\n",
    "\n",
    "That's it!\n",
    "\n",
    "So when you say: `ollama_via_openai = OpenAI(base_url='http://localhost:11434/v1', api_key='ollama')`  \n",
    "Then this will make the same endpoint calls, but to Ollama instead of OpenAI."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc7d1de3-e2ac-46ff-a302-3b4ba38c4c90",
   "metadata": {},
   "source": [
    "## Also trying the amazing reasoning model DeepSeek\n",
    "\n",
    "Here we use the version of DeepSeek-reasoner that's been distilled to 1.5B.  \n",
    "This is actually a 1.5B variant of Qwen that has been fine-tuned using synethic data generated by Deepseek R1.\n",
    "\n",
    "Other sizes of DeepSeek are [here](https://ollama.com/library/deepseek-r1) all the way up to the full 671B parameter version, which would use up 404GB of your drive and is far too large for most!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cf9eb44e-fe5b-47aa-b719-0bb63669ab3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[?25lpulling manifest â ‹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest â ™ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest â ¹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest \n",
      "pulling aabd4debf0c8... 100% â–•â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–� 1.1 GB                         \n",
      "pulling 369ca498f347... 100% â–•â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–�  387 B                         \n",
      "pulling 6e4c38e1172f... 100% â–•â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–� 1.1 KB                         \n",
      "pulling f4d24e9138dd... 100% â–•â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–�  148 B                         \n",
      "pulling a85fe2a2e58e... 100% â–•â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–�  487 B                         \n",
      "verifying sha256 digest \n",
      "writing manifest \n",
      "success \u001b[?25h\n"
     ]
    }
   ],
   "source": [
    "!ollama pull deepseek-r1:1.5b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1d3d554b-e00d-4c08-9300-45e073950a76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<think>\n",
      "Okay, so I need to find the definitions for Neural Networks, Attention, and Transformers. Hmm, where do I start?\n",
      "\n",
      "I know that in a very basic way, a neural network is this system of algorithms designed to recognize patterns and make decisions. The most famous one is maybe something like AlphaGo, right? It uses deep learning with lots of layers and neurons.\n",
      "\n",
      "Wait, but how exactly does it process data? I think each layer processes information differently, maybe through hidden layers that help extract features from the input. So perhaps neural networks are like these interconnected nodes in a graph that process input through multiple layers to produce output.\n",
      "\n",
      "Now, attention. I've heard something about this concept involving AI and NLP. It must have to do with how models focus on different parts of the input text or data. Maybe when translating, an AI uses attention to weigh the importance of words differently based on their position in a sentence. That would help it understand nuances better.\n",
      "\n",
      "Then there's Transformers. This term sticks with me because I remember reading about \"attention is all you need.\" So maybe Transformers are these models that use something called self-attention. Self-attention probably means that the model looks at itself, processing and transforming data as part of its own operations without relying on external data like images or outputs from another part. This helps in tasks like Machine Translation where it's all about understanding context.\n",
      "\n",
      "Putting this together, maybe a Neural Network is the overarching system of layers in a deep learning model that transforms input into output. Attention is then a mechanism within these models that improves performance by focusing on important parts. Transformers are advanced neural network architectures that leverage self-attention to enhance their capabilities in sequence modeling tasks.\n",
      "\n",
      "I think I have a rough idea now, but let me try to be more precise and make sure the definitions cover both the broad concepts and maybe some specifics like how each component works within it.\n",
      "</think>\n",
      "\n",
      "**Definitions of Core Concepts Behind LLMs**\n",
      "\n",
      "1. **Neural Network (NLP Framework):**\n",
      "   - A Neural Network is an artificial intelligence system composed of many layers of interconnected nodes, analogous to neurons in biological networks. These nodes process data through multiple layers, extracting increasingly complex features and transformations from the input data. It transforms input into output by gradually capturing higher-level representations.\n",
      "\n",
      "2. **Attention:**\n",
      "   - Attention is a mechanism that models how AI processes text or other structured data by assigning weights to different parts of the input at each step. It focuses on highlighting important elements, enhancing processing accuracy, and enabling better understanding through selective attention.\n",
      "\n",
      "3. **Transformers (Neural Network Architecture):**\n",
      "   - Transformers are advanced neural network architectures characterized by self-attention mechanisms. This means the model processes data internally while operating independently, crucial for tasks like Machine Translation where context understanding is vital.\n",
      "\n",
      "These components work together in LLMs. Neural Networks house layers of connections that process input into output. Attention enhances focus on key aspects of data through weighted processing. Transformers leverage their inherent self-attention to excel in sequence-dependent tasks, enabling improved performance and flexibility in various applications.\n"
     ]
    }
   ],
   "source": [
    "# This may take a few minutes to run! You should then see a fascinating \"thinking\" trace inside <think> tags, followed by some decent definitions\n",
    "\n",
    "response = ollama_via_openai.chat.completions.create(\n",
    "    model=\"deepseek-r1:1.5b\",\n",
    "    messages=[{\"role\": \"user\", \"content\": \"Please give definitions of some core concepts behind LLMs: a neural network, attention and the transformer\"}]\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1622d9bb-5c68-4d4e-9ca4-b492c751f898",
   "metadata": {},
   "source": [
    "# NOW the exercise for you\n",
    "\n",
    "Take the code from day1 and incorporate it here, to build a website summarizer that uses Llama 3.2 running locally instead of OpenAI; use either of the above approaches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0df0e4b6-88df-44e6-a4f7-1ad3597acc40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A class to represent a Webpage\n",
    "# If you're not familiar with Classes, check out the \"Intermediate Python\" notebook\n",
    "\n",
    "# Some websites need you to use proper headers when fetching them:\n",
    "headers = {\n",
    " \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/117.0.0.0 Safari/537.36\"\n",
    "}\n",
    "\n",
    "class Website:\n",
    "\n",
    "    def __init__(self, url):\n",
    "        \"\"\"\n",
    "        Create this Website object from the given url using the BeautifulSoup library\n",
    "        \"\"\"\n",
    "        self.url = url\n",
    "        response = requests.get(url, headers=headers)\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        self.title = soup.title.string if soup.title else \"No title found\"\n",
    "        for irrelevant in soup.body([\"script\", \"style\", \"img\", \"input\"]):\n",
    "            irrelevant.decompose()\n",
    "        self.text = soup.body.get_text(separator=\"\\n\", strip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "22526cff-5e2c-4850-888a-005485d80aea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quality Measures | CMS\n"
     ]
    }
   ],
   "source": [
    "cms = Website(\"https://www.cms.gov/medicare/quality/nursing-home-improvement/quality-measures\")\n",
    "print(cms.title)\n",
    "#print(cms.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7735c322-4bf2-4639-9452-adab57aa1211",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define our system prompt - you can experiment with this later, changing the last sentence to 'Respond in markdown in Spanish.\"\n",
    "\n",
    "system_prompt = \"You are an assistant that analyzes the contents of a website \\\n",
    "and provides a short summary, ignoring text that might be navigation related. \\\n",
    "Respond in markdown.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5457f597-faf0-46d6-93cd-4bd933eda57d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A function that writes a User Prompt that asks for summaries of websites:\n",
    "\n",
    "def user_prompt_for(website):\n",
    "    user_prompt = f\"You are looking at a website titled {website.title}\"\n",
    "    user_prompt += \"\\nThe contents of this website is as follows; \\\n",
    "please provide a short summary of this website in markdown. \\\n",
    "If it includes news or announcements, then summarize these too.\\n\\n\"\n",
    "    user_prompt += website.text\n",
    "    return user_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6de38216-6d1c-48c4-877b-86d403f4e0f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# See how this function creates exactly the format above\n",
    "\n",
    "def messages_for(website):\n",
    "    return [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": user_prompt_for(website)}\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d354401e-21d3-4928-9051-316a20fcdcd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# And now: call the ollama . You will get very familiar with this!\n",
    "\n",
    "def summarize(url):\n",
    "    website = Website(url)\n",
    "    response = ollama_via_openai.chat.completions.create(\n",
    "     model=\"deepseek-r1:1.5b\",\n",
    "        messages = messages_for(website)\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c575df89-8c2b-46fe-bfe3-ee13c65f3f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A function to display this nicely in the Jupyter output, using markdown\n",
    "\n",
    "def display_summary(url):\n",
    "    summary = summarize(url)\n",
    "    display(Markdown(summary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "085a03c8-2257-4cff-a9c1-c38f93b7fe26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<think>\n",
       "Okay, so I'm looking at this query, trying to figure out what's going on here. The user wrote \"Please help with File Formats and Plug-Ins\" along with some links pointing to CMS stuff. Hmm, they're probably sharing a ZIP file or an XLSX and others that are supposed to be plug-ins.\n",
       "\n",
       "I remember the initial response suggested extracting files from ZIP and UNZing the_XLSX by copying, then viewing as PDF in the MDS-3.0-QM-USERS-MANUAL-v17.0 file. They also tried opening with a text editor and using R.\n",
       "\n",
       "Wait, maybe someone wants to know how to properly manage plug-ins for their files? But wait, the user's query is about handling CMS resources, which could include things like documentation or specific tools they might use. The provided files look like they could be manual data entries or possibly some configuration files related to CMS, but it's unclear.\n",
       "\n",
       "They mentioned \"Plug-Ins,\" so maybe they're trying to automate some processes. But from the context given, this seems more like a user input without clear specifics on what exactly they need help with in terms of file handling or plug-ins.\n",
       "\n",
       "Additionally, the ZIP and XLSX files are specific types used in the MDS-3 standard for managing CMS data. Extracting files could be part of normal operations to access different aspects of CMS data. If someone isn't familiar with extracting or decoding certain files from a ZIP archive, they might look for tutorials or documentation on how such files work.\n",
       "\n",
       "I'm also thinking about whether there's more to this user's issue beyond the ZIP and XLSX files they provided. The mention of plug-ins suggests additional components or scripts that manipulate these data files in specific ways. Maybe they need help integrating analytics tools into their CMS data processing, which would involve automating file reading or parsing.\n",
       "\n",
       "Since I don't have all the details about what exactly they need assistance with regarding their ZIP and_XLSX files, it's tricky. If they can describe a specific task or problem, I could provide more detailed steps. But as it is, I'm just trying to figure out what they might be asking for based on the information given.\n",
       "\n",
       "So in summary, I should ask them clarifying questions or specify exactly what tools or processes they're dealing with when generating a better response.\n",
       "</think>\n",
       "\n",
       "It seems you're sharing some ZIP and XLSX files that may be related to CMS ( Centers for Medicare & Medicaid Services) data handling. These files could include manual entries of data in MDS-3 standard structures, configuration files, or maybe specific tools used to process CMS data.\n",
       "\n",
       "If you need help managing these files specifically, let me know what kind of assistance you’d like from below:\n",
       "\n",
       "1. **Data Management**: How do I extract specific files (ZIP and/or_XLSX) into the MDS-3 file?\n",
       "2. **Formatting / Parsing**: How can I format or parse these files in a way that aligns with how CMS data is managed?\n",
       "3. **Plug-ins/Analysis Tools**: Do these files contain plug-ins, tools for automation, or manual entries?\n",
       "\n",
       "Let me know if you'd like guidance on handling these specific aspects of CMS-related data!"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_summary(\"https://www.cms.gov/medicare/quality/nursing-home-improvement/quality-measures\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7acb7d10-5125-4962-ba04-17a4830afa3c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
